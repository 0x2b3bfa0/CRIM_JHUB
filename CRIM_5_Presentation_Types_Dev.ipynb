{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "013e77f4",
   "metadata": {},
   "source": [
    "#### Presentation Types with Hidden Types\n",
    "\n",
    "* March 2022 version\n",
    "\n",
    "    * Uses getDistance to identify `close matches` with side-by-side comparison of soggetti.  With a distance of \"1\", the soggetti `4, 1, 2, 3`, and `5, 1, 2, 3` will count as the same.  These are reported as \"flexed entries\" in a separate column.\n",
    "\n",
    "    * Labels Fuga, PEn, and ID according to time intervals.  \n",
    "    * If two entries are separated by more than 10 bars (80 offsets), the tool resets to a new pattern\n",
    "    * Finds time intervals between entries (expressed as offsets, like `8.0, 4.0, 8.0`)\n",
    "    * Finds melodic intervals between first note of successive entries in each pattern (like `P-5, P-8`)\n",
    "    * Counts number of entries\n",
    "    * Provides offset and measure/beat locations\n",
    "    * Sorts all presentation types by the order in which they appear in the piece\n",
    "    * Reports voice names of the entries, in order of their appearance\n",
    "    * Omits singleton soggetti (just one entry of a given motive in isolation)\n",
    "    \n",
    "    ALSO\n",
    "    \n",
    "    * Finds \"hidden\" types within a longer Fuga.  That is, if a 5-voice fuga also contains a PEN, it will label both of these as separate presentation type, along with all the relevant data noted above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e63a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved_csv folder already exists.\n"
     ]
    }
   ],
   "source": [
    "import intervals\n",
    "from intervals import * \n",
    "from intervals import main_objs\n",
    "import intervals.visualizations as viz\n",
    "import pandas as pd\n",
    "import re\n",
    "import altair as alt \n",
    "from ipywidgets import interact\n",
    "from pandas.io.json import json_normalize\n",
    "from pyvis.network import Network\n",
    "from IPython.display import display\n",
    "import requests\n",
    "import os\n",
    "import numpy\n",
    "import itertools\n",
    "MYDIR = (\"saved_csv\")\n",
    "CHECK_FOLDER = os.path.isdir(MYDIR)\n",
    "\n",
    "# If folder doesn't exist, then create it.\n",
    "if not CHECK_FOLDER:\n",
    "    os.makedirs(MYDIR)\n",
    "    print(\"created folder : \", MYDIR)\n",
    "\n",
    "else:\n",
    "    print(MYDIR, \"folder already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73b37ef",
   "metadata": {},
   "source": [
    "#### The following are special functions used by the classifier.  Don't change them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "833dc822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entry_int_distance(coordinates, piece: intervals.main_objs.ImportedPiece):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function finds the melodic intervals between the first notes of \n",
    "    successive entries in a given presentation type.  \n",
    "    They are represented as intervals with quality and direction, thus P-4, m3, P5, P5, M-9, P-4, P4\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    tone_list = []\n",
    "    all_tones = piece.getNoteRest()\n",
    "    \n",
    "    for item in coordinates:\n",
    "        filtered_tones = all_tones.loc[item] \n",
    "        tone_list.append(filtered_tones)\n",
    "        \n",
    "    noteObjects = [note.Note(tone) for tone in tone_list]\n",
    "    _ints = [interval.Interval(noteObjects[i], noteObjects[i + 1]) for i in range(len(noteObjects) - 1)]\n",
    "    entry_ints = []\n",
    "    \n",
    "    for _int in _ints:\n",
    "        entry_ints.append(_int.directedName)\n",
    "    \n",
    "    return entry_ints\n",
    "\n",
    "def split_by_threshold(seq, max_diff=70):  \n",
    "    \n",
    "    \"\"\"\n",
    "    This function finds gaps between sequences of matching melodic entries.  \n",
    "    The threshold is set to 70 offsets by default--under about 10 measures.\n",
    "    \n",
    "    \"\"\"\n",
    "    it = iter(seq)\n",
    "    last = next(it)\n",
    "    part = [last]\n",
    "\n",
    "    for curr in it:\n",
    "        if curr - last > max_diff:\n",
    "            yield part\n",
    "            part = []\n",
    "\n",
    "        part.append(curr)\n",
    "        last = curr\n",
    "#         print(part)\n",
    "        \n",
    "    yield part\n",
    "    \n",
    "\n",
    "def classify_by_offset(offset_diffs):\n",
    "    \"\"\"\n",
    "    This function predicts the Presentation Types. It relies of the differences between \n",
    "    the first offsets of successive melodic entries. \n",
    "    \n",
    "    If the offset differences are identical:  PEN\n",
    "    If the odd-numbered offset differences are identical:  ID, since these represent\n",
    "    situations in which the entries 1-2 have the same offset difference as entries 3-4\n",
    "    If the offset differences are all different:  FUGA\n",
    "    \n",
    "    \"\"\"\n",
    "    alt_list = offset_diffs[::2]\n",
    "\n",
    "    if len(set(offset_diffs)) == 1 and len(offset_diffs) > 1:\n",
    "        return 'PEN'\n",
    "    # elif (len(offset_difference_list) %2 != 0) and (len(set(alt_list)) == 1):\n",
    "    elif (len(offset_diffs) % 2 != 0) and (len(set(alt_list)) == 1) and (len(offset_diffs) >= 3):\n",
    "        return 'ID'\n",
    "    elif len(offset_diffs) >= 1:\n",
    "        return 'FUGA'\n",
    "\n",
    "    \n",
    "\n",
    "def temp_dict_of_details(slist, entry_array, det, matches):\n",
    "    \"\"\"\n",
    "    This function assembles various features for the presentation types \n",
    "    into a single temporary dictionary, which in turn is appended to the dataframe of 'points'\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    array = entry_array[entry_array.index.get_level_values(0).isin(slist)]\n",
    "    short_offset_list = array.index.to_list()\n",
    "    time_ints = numpy.diff(array.index).tolist()\n",
    "    voice_list = array['voice'].to_list()\n",
    "    tone_coordinates =  list(zip(short_offset_list, voice_list))\n",
    "    mel_ints = find_entry_int_distance(tone_coordinates, piece)\n",
    "    first_offset = short_offset_list[0]\n",
    "    meas_beat = det[det.index.get_level_values('Offset').isin(short_offset_list)]\n",
    "    mb2 = meas_beat.reset_index()\n",
    "    mb2['mb'] = mb2[\"Measure\"].astype(str) + \"/\" + mb2[\"Beat\"].astype(str)\n",
    "    meas_beat_list = mb2['mb'].to_list()\n",
    "    \n",
    "    # temp results for this set\n",
    "    temp = {'First_Offset': first_offset, \n",
    "                'Offsets': short_offset_list, \n",
    "                'Measures_Beats': meas_beat_list,\n",
    "                \"Soggetti\": matches,\n",
    "                'Voices': voice_list, \n",
    "                'Time_Entry_Intervals': time_ints, \n",
    "                'Melodic_Entry_Intervals': mel_ints}\n",
    "    return temp\n",
    "\n",
    "def classify_entries_as_presentation_types(piece):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function uses several other functions to classify the entries in a given piece.\n",
    "    The output is a list, in order of offset, of each presentation type, including information about\n",
    "    measures/beats\n",
    "    starting offset\n",
    "    soggetti involved \n",
    "    melodic intervals of entry\n",
    "    time intervals of entry\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    # Classifier with Functions\n",
    "    points = pd.DataFrame()\n",
    "    points2 = pd.DataFrame()\n",
    "    # new_offset_list = []\n",
    "    nr = piece.getNoteRest()\n",
    "    det = piece.detailIndex(nr, offset=True)\n",
    "\n",
    "    # durations and ngrams of durations\n",
    "    dur = piece.getDuration(df=nr)\n",
    "    dur_ng = piece.getNgrams(df=dur, n=4)\n",
    "\n",
    "    # ngrams of melodic entries\n",
    "    # for chromatic, use:\n",
    "    # piece.getMelodicEntries(interval_settings=('c', True, True), n=5)\n",
    "    mel = piece.getMelodicEntries(n=4)\n",
    "    mels_stacked = mel.stack().to_frame()\n",
    "    mels_stacked.rename(columns =  {0:\"pattern\"}, inplace = True)\n",
    "\n",
    "    # edit distance, based on side-by-side comparison of melodic ngrams\n",
    "    # gets flexed and other similar soggetti\n",
    "    dist = piece.getDistance(mel)\n",
    "    dist_stack = dist.stack().to_frame()\n",
    "\n",
    "\n",
    "    # filter distances to threshold.  <2 is good\n",
    "    filtered_dist_stack = dist_stack[dist_stack[0] < 2]\n",
    "    filtered_dist = filtered_dist_stack.reset_index()\n",
    "    filtered_dist.rename(columns =  {'level_0':\"source\", 'level_1':'match'}, inplace = True)\n",
    "\n",
    "    # Group the filtered distanced patterns\n",
    "    full_list_of_matches = filtered_dist.groupby('source')['match'].apply(list).reset_index()\n",
    "\n",
    "    for matches in full_list_of_matches[\"match\"]:\n",
    "        related_entry_list = mels_stacked[mels_stacked['pattern'].isin(matches)]\n",
    "        entry_array = related_entry_list.reset_index(level=1).rename(columns = {'level_1': \"voice\", 0: \"pattern\"})\n",
    "        offset_list = entry_array.index.to_list()\n",
    "        split_list = list(split_by_threshold(offset_list))\n",
    "        # here is the list of starting offsets of the original set of entries:  slist\n",
    "        slist = split_list[0]\n",
    "        temp = temp_dict_of_details(slist, entry_array, det, matches)\n",
    "\n",
    "        points = points.append(temp, ignore_index=True)\n",
    "        points['Presentation_Type'] = points['Time_Entry_Intervals'].apply(classify_by_offset)\n",
    "        points.drop_duplicates(subset=[\"First_Offset\"], keep='first', inplace = True)\n",
    "        points = points[points['Offsets'].apply(len) > 1]\n",
    "\n",
    "        l = len(slist)\n",
    "        if l > 2:\n",
    "            for r in range(3, l):\n",
    "    #             list_combinations = list(combinations(slist, r))\n",
    "                list_combinations = list(combinations(slist, r))\n",
    "                for slist in list_combinations:\n",
    "\n",
    "                    temp = temp_dict_of_details(slist, entry_array, det, matches)\n",
    "\n",
    "                    temp[\"Presentation_Type\"] = classify_by_offset(temp['Time_Entry_Intervals'])\n",
    "\n",
    "                    if 'PEN' in temp[\"Presentation_Type\"]:\n",
    "                        points2 = points2.append(temp, ignore_index=True)#.sort_values(\"First_Offset\")\n",
    "    #                     points = points.append(combo_temp, ignore_index=True).sort_values(\"First_Offset\")\n",
    "                        points2 = points2[points2['Offsets'].apply(len) > 1]\n",
    "                    if 'ID' in temp[\"Presentation_Type\"]:\n",
    "                        points2 = points2.append(combo_temp, ignore_index=True)#.sort_values(\"First_Offset\")\n",
    "    #                     points = points.append(combo_temp, ignore_index=True).sort_values(\"First_Offset\")\n",
    "                points2.sort_values(\"First_Offset\")\n",
    "                points2.drop_duplicates(subset=[\"First_Offset\"], keep='first', inplace = True)\n",
    "\n",
    "    points_combined = points.append(points2, ignore_index=True).sort_values(\"First_Offset\").reset_index(drop=True)\n",
    "    points_combined['Flexed_Entries'] = points_combined[\"Soggetti\"].apply(len) > 1\n",
    "    points_combined[\"Number_Entries\"] = points_combined[\"Offsets\"].apply(len)     \n",
    "    return points_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adab16b",
   "metadata": {},
   "source": [
    "## Load the Piece Here\n",
    "\n",
    "* Note that you can load from CRIM, or put a file in the **Music_Files** folder in the Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14d65484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading remote score...\n",
      "Successfully imported https://crimproject.org/mei/CRIM_Mass_0013_2.mei\n"
     ]
    }
   ],
   "source": [
    "# piece = importScore('Music_Files/Senfl_Ave_forCRIM.mei_msg.mei')\n",
    "piece = importScore('https://crimproject.org/mei/CRIM_Mass_0013_2.mei')\n",
    "# piece = importScore('Music_Files/CRIM_Mass_0007_4.mei')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff311ad",
   "metadata": {},
   "source": [
    "## Run the Classifier Here.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bf80ff3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'First_Offset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k5/k4j_550s2yq5776vgmw6r_xr0000gp/T/ipykernel_64891/1004609067.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassify_entries_as_presentation_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpiece\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/k5/k4j_550s2yq5776vgmw6r_xr0000gp/T/ipykernel_64891/930379780.py\u001b[0m in \u001b[0;36mclassify_entries_as_presentation_types\u001b[0;34m(piece)\u001b[0m\n\u001b[1;32m    176\u001b[0m                         \u001b[0mpoints2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoints2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombo_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.sort_values(\"First_Offset\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m#                     points = points.append(combo_temp, ignore_index=True).sort_values(\"First_Offset\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                 \u001b[0mpoints2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"First_Offset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0mpoints2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"First_Offset\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'first'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/intervals_dev/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   5453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5454\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5455\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5457\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/intervals_dev/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1682\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1684\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'First_Offset'"
     ]
    }
   ],
   "source": [
    "classify_entries_as_presentation_types(piece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fde28ed1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'First_Offset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k5/k4j_550s2yq5776vgmw6r_xr0000gp/T/ipykernel_64891/4178578768.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_entries_as_presentation_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpiece\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/k5/k4j_550s2yq5776vgmw6r_xr0000gp/T/ipykernel_64891/930379780.py\u001b[0m in \u001b[0;36mclassify_entries_as_presentation_types\u001b[0;34m(piece)\u001b[0m\n\u001b[1;32m    176\u001b[0m                         \u001b[0mpoints2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoints2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombo_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.sort_values(\"First_Offset\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m#                     points = points.append(combo_temp, ignore_index=True).sort_values(\"First_Offset\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                 \u001b[0mpoints2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"First_Offset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0mpoints2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"First_Offset\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'first'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/intervals_dev/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   5453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5454\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5455\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5457\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/intervals_dev/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1682\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1684\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'First_Offset'"
     ]
    }
   ],
   "source": [
    "output = classify_entries_as_presentation_types(piece)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0778550c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First_Offset</th>\n",
       "      <th>Measures_Beats</th>\n",
       "      <th>Melodic_Entry_Intervals</th>\n",
       "      <th>Offsets</th>\n",
       "      <th>Soggetti</th>\n",
       "      <th>Time_Entry_Intervals</th>\n",
       "      <th>Voices</th>\n",
       "      <th>Presentation_Type</th>\n",
       "      <th>Flexed_Entries</th>\n",
       "      <th>Number_Entries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138.0</td>\n",
       "      <td>[18/2.0, 19/4.0, 21/2.0]</td>\n",
       "      <td>[P1, M9]</td>\n",
       "      <td>[138.0, 150.0, 162.0]</td>\n",
       "      <td>[-2, -3, 2, 2]</td>\n",
       "      <td>[12.0, 12.0]</td>\n",
       "      <td>[PrimusTenor, SecundusTenor, Superius]</td>\n",
       "      <td>PEN</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142.0</td>\n",
       "      <td>[18/4.0, 19/4.0, 20/4.0]</td>\n",
       "      <td>[P4, P5]</td>\n",
       "      <td>[142.0, 150.0, 158.0]</td>\n",
       "      <td>[-2, -3, 2, 2]</td>\n",
       "      <td>[8.0, 8.0]</td>\n",
       "      <td>[Bassus, SecundusTenor, Contratenor]</td>\n",
       "      <td>PEN</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>314.0</td>\n",
       "      <td>[40/2.0, 41/2.0, 42/2.0]</td>\n",
       "      <td>[P8, P-8]</td>\n",
       "      <td>[314.0, 322.0, 330.0]</td>\n",
       "      <td>[2, -3, 2, 3, 2, -3, 2, 4]</td>\n",
       "      <td>[8.0, 8.0]</td>\n",
       "      <td>[Bassus, Superius, SecundusTenor]</td>\n",
       "      <td>PEN</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>322.0</td>\n",
       "      <td>[41/2.0, 42/2.0, 43/2.0]</td>\n",
       "      <td>[P-8, P-5]</td>\n",
       "      <td>[322.0, 330.0, 338.0]</td>\n",
       "      <td>[2, -3, 2, 3, 2, -3, 2, 4]</td>\n",
       "      <td>[8.0, 8.0]</td>\n",
       "      <td>[Superius, SecundusTenor, Bassus]</td>\n",
       "      <td>PEN</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>330.0</td>\n",
       "      <td>[42/2.0, 43/4.0, 45/2.0]</td>\n",
       "      <td>[d5, M7]</td>\n",
       "      <td>[330.0, 342.0, 354.0]</td>\n",
       "      <td>[2, -3, 2, 3, 2, -3, 2, 4]</td>\n",
       "      <td>[12.0, 12.0]</td>\n",
       "      <td>[SecundusTenor, Contratenor, Superius]</td>\n",
       "      <td>PEN</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>338.0</td>\n",
       "      <td>[43/2.0, 44/4.0, 46/2.0]</td>\n",
       "      <td>[P4, P5]</td>\n",
       "      <td>[338.0, 350.0, 362.0]</td>\n",
       "      <td>[2, -3, 2, 3, 2, -3, 2, 4]</td>\n",
       "      <td>[12.0, 12.0]</td>\n",
       "      <td>[Bassus, PrimusTenor, SecundusTenor]</td>\n",
       "      <td>PEN</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>394.0</td>\n",
       "      <td>[50/2.0, 51/4.0, 53/2.0]</td>\n",
       "      <td>[P5, P1]</td>\n",
       "      <td>[394.0, 406.0, 418.0]</td>\n",
       "      <td>[3, 2, -3, -2]</td>\n",
       "      <td>[12.0, 12.0]</td>\n",
       "      <td>[SecundusTenor, PrimusTenor, SecundusTenor]</td>\n",
       "      <td>PEN</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>430.0</td>\n",
       "      <td>[54/4.0, 56/4.0, 58/4.0]</td>\n",
       "      <td>[M-2, P5]</td>\n",
       "      <td>[430.0, 446.0, 462.0]</td>\n",
       "      <td>[4, 1, -2, 2, 4, 1, -2, 1]</td>\n",
       "      <td>[16.0, 16.0]</td>\n",
       "      <td>[PrimusTenor, SecundusTenor, PrimusTenor]</td>\n",
       "      <td>PEN</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>434.0</td>\n",
       "      <td>[55/2.0, 58/4.0, 62/2.0]</td>\n",
       "      <td>[P1, P-8]</td>\n",
       "      <td>[434.0, 462.0, 490.0]</td>\n",
       "      <td>[4, 1, -2, 2, 4, 1, -2, 1]</td>\n",
       "      <td>[28.0, 28.0]</td>\n",
       "      <td>[Contratenor, PrimusTenor, Bassus]</td>\n",
       "      <td>PEN</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>442.0</td>\n",
       "      <td>[56/2.0, 60/4.0, 65/2.0]</td>\n",
       "      <td>[P-8, M-6]</td>\n",
       "      <td>[442.0, 478.0, 514.0]</td>\n",
       "      <td>[4, 1, -2, 2, 4, 1, -2, 1, 5, 1, -2, 2]</td>\n",
       "      <td>[36.0, 36.0]</td>\n",
       "      <td>[Superius, SecundusTenor, Bassus]</td>\n",
       "      <td>PEN</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>446.0</td>\n",
       "      <td>[56/4.0, 58/4.0, 60/4.0]</td>\n",
       "      <td>[P5, P-4]</td>\n",
       "      <td>[446.0, 462.0, 478.0]</td>\n",
       "      <td>[4, 1, -2, 2, 4, 1, -2, 1]</td>\n",
       "      <td>[16.0, 16.0]</td>\n",
       "      <td>[SecundusTenor, PrimusTenor, SecundusTenor]</td>\n",
       "      <td>PEN</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>462.0</td>\n",
       "      <td>[58/4.0, 62/2.0, 65/4.0]</td>\n",
       "      <td>[P-8, P4]</td>\n",
       "      <td>[462.0, 490.0, 518.0]</td>\n",
       "      <td>[4, 1, -2, 2, 4, 1, -2, 1]</td>\n",
       "      <td>[28.0, 28.0]</td>\n",
       "      <td>[PrimusTenor, Bassus, PrimusTenor]</td>\n",
       "      <td>PEN</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>478.0</td>\n",
       "      <td>[60/4.0, 62/3.0, 64/2.0]</td>\n",
       "      <td>[M-2, P1]</td>\n",
       "      <td>[478.0, 492.0, 506.0]</td>\n",
       "      <td>[4, 1, -2, 2, 5, 1, -2, 2, 5, 1, -3, 2]</td>\n",
       "      <td>[14.0, 14.0]</td>\n",
       "      <td>[SecundusTenor, PrimusTenor, SecundusTenor]</td>\n",
       "      <td>PEN</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>638.0</td>\n",
       "      <td>[79/4.0, 81/2.0, 82/4.0]</td>\n",
       "      <td>[P-5, P12]</td>\n",
       "      <td>[638.0, 650.0, 662.0]</td>\n",
       "      <td>[3, -2, -2, -2]</td>\n",
       "      <td>[12.0, 12.0]</td>\n",
       "      <td>[SecundusTenor, Bassus, Superius]</td>\n",
       "      <td>PEN</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>918.0</td>\n",
       "      <td>[114/4.0, 117/2.0, 119/4.0]</td>\n",
       "      <td>[P12, P-8]</td>\n",
       "      <td>[918.0, 938.0, 958.0]</td>\n",
       "      <td>[1, -2, -3, 3]</td>\n",
       "      <td>[20.0, 20.0]</td>\n",
       "      <td>[Bassus, Superius, Bassus]</td>\n",
       "      <td>PEN</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>978.0</td>\n",
       "      <td>[122/2.0, 122/4.0, 123/2.0]</td>\n",
       "      <td>[P1, P8]</td>\n",
       "      <td>[978.0, 982.0, 986.0]</td>\n",
       "      <td>[2, -2, -3, 2]</td>\n",
       "      <td>[4.0, 4.0]</td>\n",
       "      <td>[SecundusTenor, PrimusTenor, Superius]</td>\n",
       "      <td>PEN</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>986.0</td>\n",
       "      <td>[123/2.0, 125/1.0, 126/4.0]</td>\n",
       "      <td>[P-5, P-5]</td>\n",
       "      <td>[986.0, 1000.0, 1014.0]</td>\n",
       "      <td>[2, -2, -3, 2]</td>\n",
       "      <td>[14.0, 14.0]</td>\n",
       "      <td>[Superius, Contratenor, SecundusTenor]</td>\n",
       "      <td>PEN</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    First_Offset               Measures_Beats Melodic_Entry_Intervals  \\\n",
       "3          138.0     [18/2.0, 19/4.0, 21/2.0]                [P1, M9]   \n",
       "4          142.0     [18/4.0, 19/4.0, 20/4.0]                [P4, P5]   \n",
       "6          314.0     [40/2.0, 41/2.0, 42/2.0]               [P8, P-8]   \n",
       "7          322.0     [41/2.0, 42/2.0, 43/2.0]              [P-8, P-5]   \n",
       "8          330.0     [42/2.0, 43/4.0, 45/2.0]                [d5, M7]   \n",
       "9          338.0     [43/2.0, 44/4.0, 46/2.0]                [P4, P5]   \n",
       "12         394.0     [50/2.0, 51/4.0, 53/2.0]                [P5, P1]   \n",
       "13         430.0     [54/4.0, 56/4.0, 58/4.0]               [M-2, P5]   \n",
       "15         434.0     [55/2.0, 58/4.0, 62/2.0]               [P1, P-8]   \n",
       "16         442.0     [56/2.0, 60/4.0, 65/2.0]              [P-8, M-6]   \n",
       "17         446.0     [56/4.0, 58/4.0, 60/4.0]               [P5, P-4]   \n",
       "19         462.0     [58/4.0, 62/2.0, 65/4.0]               [P-8, P4]   \n",
       "20         478.0     [60/4.0, 62/3.0, 64/2.0]               [M-2, P1]   \n",
       "23         638.0     [79/4.0, 81/2.0, 82/4.0]              [P-5, P12]   \n",
       "26         918.0  [114/4.0, 117/2.0, 119/4.0]              [P12, P-8]   \n",
       "27         978.0  [122/2.0, 122/4.0, 123/2.0]                [P1, P8]   \n",
       "29         986.0  [123/2.0, 125/1.0, 126/4.0]              [P-5, P-5]   \n",
       "\n",
       "                    Offsets                                 Soggetti  \\\n",
       "3     [138.0, 150.0, 162.0]                           [-2, -3, 2, 2]   \n",
       "4     [142.0, 150.0, 158.0]                           [-2, -3, 2, 2]   \n",
       "6     [314.0, 322.0, 330.0]               [2, -3, 2, 3, 2, -3, 2, 4]   \n",
       "7     [322.0, 330.0, 338.0]               [2, -3, 2, 3, 2, -3, 2, 4]   \n",
       "8     [330.0, 342.0, 354.0]               [2, -3, 2, 3, 2, -3, 2, 4]   \n",
       "9     [338.0, 350.0, 362.0]               [2, -3, 2, 3, 2, -3, 2, 4]   \n",
       "12    [394.0, 406.0, 418.0]                           [3, 2, -3, -2]   \n",
       "13    [430.0, 446.0, 462.0]               [4, 1, -2, 2, 4, 1, -2, 1]   \n",
       "15    [434.0, 462.0, 490.0]               [4, 1, -2, 2, 4, 1, -2, 1]   \n",
       "16    [442.0, 478.0, 514.0]  [4, 1, -2, 2, 4, 1, -2, 1, 5, 1, -2, 2]   \n",
       "17    [446.0, 462.0, 478.0]               [4, 1, -2, 2, 4, 1, -2, 1]   \n",
       "19    [462.0, 490.0, 518.0]               [4, 1, -2, 2, 4, 1, -2, 1]   \n",
       "20    [478.0, 492.0, 506.0]  [4, 1, -2, 2, 5, 1, -2, 2, 5, 1, -3, 2]   \n",
       "23    [638.0, 650.0, 662.0]                          [3, -2, -2, -2]   \n",
       "26    [918.0, 938.0, 958.0]                           [1, -2, -3, 3]   \n",
       "27    [978.0, 982.0, 986.0]                           [2, -2, -3, 2]   \n",
       "29  [986.0, 1000.0, 1014.0]                           [2, -2, -3, 2]   \n",
       "\n",
       "   Time_Entry_Intervals                                       Voices  \\\n",
       "3          [12.0, 12.0]       [PrimusTenor, SecundusTenor, Superius]   \n",
       "4            [8.0, 8.0]         [Bassus, SecundusTenor, Contratenor]   \n",
       "6            [8.0, 8.0]            [Bassus, Superius, SecundusTenor]   \n",
       "7            [8.0, 8.0]            [Superius, SecundusTenor, Bassus]   \n",
       "8          [12.0, 12.0]       [SecundusTenor, Contratenor, Superius]   \n",
       "9          [12.0, 12.0]         [Bassus, PrimusTenor, SecundusTenor]   \n",
       "12         [12.0, 12.0]  [SecundusTenor, PrimusTenor, SecundusTenor]   \n",
       "13         [16.0, 16.0]    [PrimusTenor, SecundusTenor, PrimusTenor]   \n",
       "15         [28.0, 28.0]           [Contratenor, PrimusTenor, Bassus]   \n",
       "16         [36.0, 36.0]            [Superius, SecundusTenor, Bassus]   \n",
       "17         [16.0, 16.0]  [SecundusTenor, PrimusTenor, SecundusTenor]   \n",
       "19         [28.0, 28.0]           [PrimusTenor, Bassus, PrimusTenor]   \n",
       "20         [14.0, 14.0]  [SecundusTenor, PrimusTenor, SecundusTenor]   \n",
       "23         [12.0, 12.0]            [SecundusTenor, Bassus, Superius]   \n",
       "26         [20.0, 20.0]                   [Bassus, Superius, Bassus]   \n",
       "27           [4.0, 4.0]       [SecundusTenor, PrimusTenor, Superius]   \n",
       "29         [14.0, 14.0]       [Superius, Contratenor, SecundusTenor]   \n",
       "\n",
       "   Presentation_Type  Flexed_Entries  Number_Entries  \n",
       "3                PEN           False               3  \n",
       "4                PEN           False               3  \n",
       "6                PEN            True               3  \n",
       "7                PEN            True               3  \n",
       "8                PEN            True               3  \n",
       "9                PEN            True               3  \n",
       "12               PEN           False               3  \n",
       "13               PEN            True               3  \n",
       "15               PEN            True               3  \n",
       "16               PEN            True               3  \n",
       "17               PEN            True               3  \n",
       "19               PEN            True               3  \n",
       "20               PEN            True               3  \n",
       "23               PEN           False               3  \n",
       "26               PEN           False               3  \n",
       "27               PEN           False               3  \n",
       "29               PEN           False               3  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = output.loc[output['Presentation_Type'] == \"PEN\"] \n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902ffd4a",
   "metadata": {},
   "source": [
    "#### Below is Development Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ecea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this works with ONE list of offsets\n",
    "\n",
    "points2 = pd.DataFrame()\n",
    "split_list = [90.0, 94.0, 102.0, 106.0, 134.0, 146.0, 162.0]\n",
    "\n",
    "l = len(split_list)  \n",
    "for r in range(3, l):\n",
    "    list_combinations = list(combinations(split_list, r))\n",
    "#             combo_time_ints = []\n",
    "    for combo in list_combinations:\n",
    "        combo_time_ints = numpy.diff(combo).tolist()\n",
    "        combo_array = entry_array[entry_array.index.get_level_values(0).isin(combo)]\n",
    "        combo_voice_list = combo_array['voice'].to_list()\n",
    "        combo_patterns = combo_array['pattern']\n",
    "        unique_combo_patterns = list(set(combo_patterns))\n",
    "        tone_coordinates =  list(zip(combo, combo_voice_list))\n",
    "# tone_coordinates.ffill(inplace=True)\n",
    "        mel_ints = find_entry_int_distance(tone_coordinates, piece)\n",
    "        hidden_type = classify_by_offset(combo_time_ints)\n",
    "\n",
    "        meas_beat = det[det.index.get_level_values('Offset').isin(combo)]\n",
    "        mb2 = meas_beat.reset_index()\n",
    "        mb2['mb'] = mb2[\"Measure\"].astype(str) + \"/\" + mb2[\"Beat\"].astype(str)\n",
    "        meas_beat_list = mb2['mb'].to_list()\n",
    "\n",
    "        combo_temp = {'First_Offset': combo[0], \n",
    "            'Offsets': combo, \n",
    "            'Measures_Beats': meas_beat_list,\n",
    "            'Presentation_Type': hidden_type,\n",
    "            \"Soggetti\": unique_combo_patterns,\n",
    "            'Voices': combo_voice_list, \n",
    "            'Time_Entry_Intervals': combo_time_ints, \n",
    "            'Melodic_Entry_Intervals': mel_ints}\n",
    "\n",
    "        if 'PEN' in hidden_type:\n",
    "            points2 = points2.append(combo_temp, ignore_index=True).sort_values(\"First_Offset\")\n",
    "#             points2 = points2[points2['Offsets'].apply(len) > 1]\n",
    "        if 'ID' in hidden_type:\n",
    "            points2 = points2.append(combo_temp, ignore_index=True).sort_values(\"First_Offset\")\n",
    "#             points2 = points2[points2['Offsets'].apply(len) > 1]\n",
    "        \n",
    "        \n",
    "# combo_time_ints\n",
    "# combo_array\n",
    "# # combo_voice_list\n",
    "# # combo_patterns\n",
    "# # unique_combo_patterns\n",
    "# # tone_coordinates\n",
    "# # mel_ints\n",
    "# # combo_temp\n",
    "points2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48329fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this finds hidden fugas.  \n",
    "# try to run each of the first set of results above ('points') through this tool, then append the \n",
    "# new results to the full DF, and sort again.  \n",
    "# mark each long pattern with 'has hidden pattern' boolean?  or ?\n",
    "\n",
    "sample_list = points[\"Offsets\"][4]\n",
    "\n",
    "hidden_pts = []\n",
    "n = len(sample_list)\n",
    "for item in range(3, n):\n",
    "    list_combinations = list(combinations(sample_list, item))\n",
    "    for group in list_combinations:\n",
    "        group_time_ints = numpy.diff(group).tolist()\n",
    "        hidden_type = classify_by_offset(group_time_ints)\n",
    "        if 'PEN' in hidden_type:\n",
    "            print(group)\n",
    "            print(group_time_ints)\n",
    "            print(hidden_type)\n",
    "            hidden_pts.append(group_time_ints)\n",
    "        if 'ID' in hidden_type:\n",
    "            print(group)\n",
    "            print(group_time_ints)\n",
    "            print(hidden_type)\n",
    "            hidden_pts.append(group_time_ints)\n",
    "        \n",
    "\n",
    "list_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9bea414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_entries_as_presentation_types(piece):\n",
    "    # Classifier with Functions\n",
    "    points = pd.DataFrame()\n",
    "    points2 = pd.DataFrame()\n",
    "    # new_offset_list = []\n",
    "    nr = piece.getNoteRest()\n",
    "    det = piece.detailIndex(nr, offset=True)\n",
    "\n",
    "    # durations and ngrams of durations\n",
    "    dur = piece.getDuration(df=nr)\n",
    "    dur_ng = piece.getNgrams(df=dur, n=4)\n",
    "\n",
    "    # ngrams of melodic entries\n",
    "    # for chromatic, use:\n",
    "    # piece.getMelodicEntries(interval_settings=('c', True, True), n=5)\n",
    "    mel = piece.getMelodicEntries(n=4)\n",
    "    mels_stacked = mel.stack().to_frame()\n",
    "    mels_stacked.rename(columns =  {0:\"pattern\"}, inplace = True)\n",
    "\n",
    "    # edit distance, based on side-by-side comparison of melodic ngrams\n",
    "    # gets flexed and other similar soggetti\n",
    "    dist = piece.getDistance(mel)\n",
    "    dist_stack = dist.stack().to_frame()\n",
    "\n",
    "\n",
    "    # filter distances to threshold.  <2 is good\n",
    "    filtered_dist_stack = dist_stack[dist_stack[0] < 2]\n",
    "    filtered_dist = filtered_dist_stack.reset_index()\n",
    "    filtered_dist.rename(columns =  {'level_0':\"source\", 'level_1':'match'}, inplace = True)\n",
    "\n",
    "    # Group the filtered distanced patterns\n",
    "    full_list_of_matches = filtered_dist.groupby('source')['match'].apply(list).reset_index()\n",
    "\n",
    "    for matches in full_list_of_matches[\"match\"]:\n",
    "        related_entry_list = mels_stacked[mels_stacked['pattern'].isin(matches)]\n",
    "        entry_array = related_entry_list.reset_index(level=1).rename(columns = {'level_1': \"voice\", 0: \"pattern\"})\n",
    "        offset_list = entry_array.index.to_list()\n",
    "        split_list = list(split_by_threshold(offset_list))\n",
    "        # here is the list of starting offsets of the original set of entries:  slist\n",
    "        slist = split_list[0]\n",
    "        temp = temp_dict_of_details(slist, entry_array, det, matches)\n",
    "\n",
    "        points = points.append(temp, ignore_index=True)\n",
    "        points['Presentation_Type'] = points['Time_Entry_Intervals'].apply(classify_by_offset)\n",
    "        points.drop_duplicates(subset=[\"First_Offset\"], keep='first', inplace = True)\n",
    "        points = points[points['Offsets'].apply(len) > 1]\n",
    "\n",
    "        l = len(slist)\n",
    "        if l > 2:\n",
    "            for r in range(3, l):\n",
    "    #             list_combinations = list(combinations(slist, r))\n",
    "                list_combinations = list(combinations(slist, r))\n",
    "                for slist in list_combinations:\n",
    "\n",
    "                    temp = temp_dict_of_details(slist, entry_array, det, matches)\n",
    "\n",
    "                    temp[\"Presentation_Type\"] = classify_by_offset(temp['Time_Entry_Intervals'])\n",
    "\n",
    "                    if 'PEN' in temp[\"Presentation_Type\"]:\n",
    "                        points2 = points2.append(temp, ignore_index=True)#.sort_values(\"First_Offset\")\n",
    "    #                     points = points.append(combo_temp, ignore_index=True).sort_values(\"First_Offset\")\n",
    "                        points2 = points2[points2['Offsets'].apply(len) > 1]\n",
    "                    if 'ID' in temp[\"Presentation_Type\"]:\n",
    "                        points2 = points2.append(combo_temp, ignore_index=True)#.sort_values(\"First_Offset\")\n",
    "    #                     points = points.append(combo_temp, ignore_index=True).sort_values(\"First_Offset\")\n",
    "                points2.sort_values(\"First_Offset\")\n",
    "                points2.drop_duplicates(subset=[\"First_Offset\"], keep='first', inplace = True)\n",
    "\n",
    "    points_combined = points.append(points2, ignore_index=True).sort_values(\"First_Offset\").reset_index(drop=True)\n",
    "    points_combined['Flexed_Entries'] = points_combined[\"Soggetti\"].apply(len) > 1\n",
    "    points_combined[\"Number_Entries\"] = points[\"Offsets\"].apply(len)     \n",
    "    return points2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5097c29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test works\n",
    "\n",
    "\n",
    "l = len(split_list[0])  \n",
    "for item in range(3, l):\n",
    "    list_combinations = list(combinations(sample_list, item))\n",
    "    for group in list_combinations:\n",
    "        group_time_ints = numpy.diff(group).tolist()\n",
    "        hidden_type = classify_by_offset(group_time_ints)\n",
    "        for item in group:\n",
    "#         print(item)\n",
    "        array = group[entry_array.index.get_level_values(0).isin(item)]\n",
    "        short_offset_list = array.index.to_list()\n",
    "        time_ints = numpy.diff(array.index).tolist()\n",
    "        voice_list = array['voice'].to_list()\n",
    "        if 'PEN' in hidden_type:\n",
    "            print(group)\n",
    "            print(group_time_ints)\n",
    "            print(hidden_type)\n",
    "            hidden_pts.append(group_time_ints)\n",
    "        if 'ID' in hidden_type:\n",
    "            print(group)\n",
    "            print(group_time_ints)\n",
    "            print(hidden_type)\n",
    "            hidden_pts.append(group_time_ints)\n",
    "# len(split_list[0])           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
